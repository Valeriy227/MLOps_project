{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataframe is 3066766\n",
      "Column names\n",
      "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
      "      dtype='object')\n",
      "Column types\n",
      "VendorID                          int64\n",
      "tpep_pickup_datetime     datetime64[ns]\n",
      "tpep_dropoff_datetime    datetime64[ns]\n",
      "passenger_count                 float64\n",
      "trip_distance                   float64\n",
      "RatecodeID                      float64\n",
      "store_and_fwd_flag               object\n",
      "PULocationID                      int64\n",
      "DOLocationID                      int64\n",
      "payment_type                      int64\n",
      "fare_amount                     float64\n",
      "extra                           float64\n",
      "mta_tax                         float64\n",
      "tip_amount                      float64\n",
      "tolls_amount                    float64\n",
      "improvement_surcharge           float64\n",
      "total_amount                    float64\n",
      "congestion_surcharge            float64\n",
      "airport_fee                     float64\n",
      "dtype: object\n",
      "Dropping total_amount and tolls_amount (they include the target)\n",
      "#unique in VendorID is 2\n",
      "#unique in tpep_pickup_datetime is 1610975\n",
      "#unique in tpep_dropoff_datetime is 1611319\n",
      "#unique in passenger_count is 10\n",
      "#unique in trip_distance is 4387\n",
      "#unique in RatecodeID is 7\n",
      "#unique in store_and_fwd_flag is 2\n",
      "#unique in PULocationID is 257\n",
      "#unique in DOLocationID is 261\n",
      "#unique in payment_type is 5\n",
      "#unique in fare_amount is 6873\n",
      "#unique in extra is 68\n",
      "#unique in mta_tax is 10\n",
      "#unique in tip_amount is 4036\n",
      "#unique in improvement_surcharge is 5\n",
      "#unique in congestion_surcharge is 3\n",
      "#unique in airport_fee is 3\n",
      "percentage of NAs in VendorID is 0.0%\n",
      "percentage of NAs in tpep_pickup_datetime is 0.0%\n",
      "percentage of NAs in tpep_dropoff_datetime is 0.0%\n",
      "percentage of NAs in passenger_count is 2.3%\n",
      "percentage of NAs in trip_distance is 0.0%\n",
      "percentage of NAs in RatecodeID is 2.3%\n",
      "percentage of NAs in store_and_fwd_flag is 2.3%\n",
      "percentage of NAs in PULocationID is 0.0%\n",
      "percentage of NAs in DOLocationID is 0.0%\n",
      "percentage of NAs in payment_type is 0.0%\n",
      "percentage of NAs in fare_amount is 0.0%\n",
      "percentage of NAs in extra is 0.0%\n",
      "percentage of NAs in mta_tax is 0.0%\n",
      "percentage of NAs in tip_amount is 0.0%\n",
      "percentage of NAs in improvement_surcharge is 0.0%\n",
      "percentage of NAs in congestion_surcharge is 2.3%\n",
      "percentage of NAs in airport_fee is 2.3%\n",
      "Droping rows with missing values\n",
      "Now length of dataframe is 2995023\n",
      "Convert Store_and_fwd_flag to number\n",
      "Droping rows with anomalous values of VendorID\n",
      "Now length of dataframe is 2995023\n",
      "Droping rows with anomalous values of tpep_pickup_datetime\n",
      "Now length of dataframe is 2965075\n",
      "Droping rows with anomalous values of tpep_dropoff_datetime\n",
      "Now length of dataframe is 2935425\n",
      "Droping rows with anomalous values of passenger_count\n",
      "Now length of dataframe is 2935405\n",
      "Droping rows with anomalous values of trip_distance\n",
      "Now length of dataframe is 2920765\n",
      "Droping rows with anomalous values of RatecodeID\n",
      "Now length of dataframe is 2908138\n",
      "Droping rows with anomalous values of store_and_fwd_flag\n",
      "Now length of dataframe is 2908138\n",
      "Droping rows with anomalous values of PULocationID\n",
      "Now length of dataframe is 2900010\n",
      "Droping rows with anomalous values of DOLocationID\n",
      "Now length of dataframe is 2888032\n",
      "Droping rows with anomalous values of payment_type\n",
      "Now length of dataframe is 2888032\n",
      "Droping rows with anomalous values of fare_amount\n",
      "Now length of dataframe is 2860039\n",
      "Droping rows with anomalous values of extra\n",
      "Now length of dataframe is 2848917\n",
      "Droping rows with anomalous values of mta_tax\n",
      "Now length of dataframe is 2835301\n",
      "Droping rows with anomalous values of tip_amount\n",
      "Now length of dataframe is 2821395\n",
      "Droping rows with anomalous values of improvement_surcharge\n",
      "Now length of dataframe is 2817375\n",
      "Droping rows with anomalous values of congestion_surcharge\n",
      "Now length of dataframe is 2817375\n",
      "Droping rows with anomalous values of airport_fee\n",
      "Now length of dataframe is 2817375\n",
      "Dropping tip_amount from dataframe\n",
      "Dropping tpep_pickup_datetime and tpep_dropoff_datetime\n",
      "Variable VendorID is categorial, doing one hot encoding of it\n",
      "Variable passenger_count is categorial, doing one hot encoding of it\n",
      "Variable RatecodeID is categorial, doing one hot encoding of it\n",
      "Variable store_and_fwd_flag is categorial, doing one hot encoding of it\n",
      "Variable PULocationID is categorial, doing one hot encoding of it\n",
      "Variable DOLocationID is categorial, doing one hot encoding of it\n",
      "Variable payment_type is categorial, doing one hot encoding of it\n",
      "Variable extra is categorial, doing one hot encoding of it\n",
      "Variable mta_tax is categorial, doing one hot encoding of it\n",
      "Variable improvement_surcharge is categorial, doing one hot encoding of it\n",
      "Variable congestion_surcharge is categorial, doing one hot encoding of it\n",
      "Variable airport_fee is categorial, doing one hot encoding of it\n",
      "Correlations with target:\n",
      "trip_distance 0.35\n",
      "fare_amount 0.36\n",
      "duration 0.07\n",
      "VendorID==2 0.04\n",
      "VendorID==1 -0.04\n",
      "passenger_count==4.0 -0.02\n",
      "passenger_count==0.0 -0.02\n",
      "RatecodeID==1.0 -0.19\n",
      "RatecodeID==2.0 0.19\n",
      "PULocationID==48 -0.02\n",
      "PULocationID==13 0.02\n",
      "PULocationID==264 0.03\n",
      "PULocationID==137 -0.02\n",
      "PULocationID==132 0.11\n",
      "PULocationID==263 -0.02\n",
      "PULocationID==100 -0.02\n",
      "PULocationID==237 -0.03\n",
      "PULocationID==141 -0.02\n",
      "PULocationID==138 0.16\n",
      "PULocationID==70 0.05\n",
      "PULocationID==74 -0.03\n",
      "PULocationID==42 -0.03\n",
      "PULocationID==41 -0.03\n",
      "PULocationID==75 -0.03\n",
      "PULocationID==145 -0.03\n",
      "PULocationID==193 -0.03\n",
      "DOLocationID==87 0.03\n",
      "DOLocationID==28 -0.02\n",
      "DOLocationID==80 0.02\n",
      "DOLocationID==13 0.02\n",
      "DOLocationID==48 -0.02\n",
      "DOLocationID==89 0.02\n",
      "DOLocationID==93 -0.04\n",
      "DOLocationID==186 -0.02\n",
      "DOLocationID==75 -0.02\n",
      "DOLocationID==132 0.04\n",
      "DOLocationID==231 0.02\n",
      "DOLocationID==25 0.03\n",
      "DOLocationID==61 0.02\n",
      "DOLocationID==100 -0.02\n",
      "DOLocationID==237 -0.02\n",
      "DOLocationID==138 0.10\n",
      "DOLocationID==37 0.02\n",
      "DOLocationID==74 -0.02\n",
      "DOLocationID==256 0.02\n",
      "DOLocationID==181 0.05\n",
      "DOLocationID==112 0.03\n",
      "DOLocationID==10 -0.03\n",
      "DOLocationID==255 0.04\n",
      "DOLocationID==189 0.03\n",
      "DOLocationID==97 0.02\n",
      "DOLocationID==243 0.02\n",
      "DOLocationID==49 0.03\n",
      "DOLocationID==33 0.03\n",
      "DOLocationID==52 0.02\n",
      "DOLocationID==193 -0.03\n",
      "DOLocationID==39 -0.02\n",
      "DOLocationID==130 -0.03\n",
      "DOLocationID==36 0.02\n",
      "DOLocationID==217 -0.02\n",
      "DOLocationID==215 -0.03\n",
      "DOLocationID==216 -0.02\n",
      "DOLocationID==82 -0.02\n",
      "DOLocationID==40 0.02\n",
      "DOLocationID==76 -0.02\n",
      "DOLocationID==257 0.02\n",
      "DOLocationID==219 -0.02\n",
      "payment_type==2 -0.73\n",
      "payment_type==1 0.75\n",
      "payment_type==3 -0.10\n",
      "payment_type==4 -0.12\n",
      "extra==0.0 -0.06\n",
      "extra==3.75 0.06\n",
      "extra==2.5 -0.04\n",
      "extra==5.0 0.10\n",
      "extra==8.75 0.07\n",
      "extra==7.5 0.09\n",
      "extra==6.0 0.08\n",
      "congestion_surcharge==0.0 -0.06\n",
      "congestion_surcharge==2.5 0.06\n",
      "airport_fee==0.0 -0.20\n",
      "airport_fee==1.25 0.20\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAHFCAYAAAAudofcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRdElEQVR4nO3deVyVdf7//+eJ5bAoJ1wAjzliYxmGNYalaIamYK5Ny9dmSJLJYTS3CM20ZibTcsvU0snW0UrNagynMgmyxExxGyhxa9PABLFEUERAvH5/9OP6eAQR6FJEH/fb7dzyvK/Xua73efs+nmfXdmyGYRgCAACAZa6o7w4AAABcaghYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFi4rCxevFg2m818uLu766qrrtJf/vIX/fTTT/XdPeCiNXv2bNlsNu3bt6++uwI0CO713QGgPixatEjXXXediouLtW7dOk2fPl2pqanavn27fH1967t7AIAGjoCFy1JoaKg6deokSerZs6fKy8s1depUrVy5Uvfff3899w4A0NBxiBCQ1KVLF0nSjz/+KEk6dOiQRo4cqfbt26tRo0YKCAjQ7bffri+++KLSa0tKSjRlyhSFhITIy8tLTZs2Vc+ePbVhwwaz5vTDkmc+goODzbp9+/bJZrNp1qxZeuaZZ/S73/1OXl5e6tSpk9asWVNp299++62io6MVEBAgu92ukJAQ/etf/6ryPU6ePLnK7ffo0aNS7aeffqpevXrJz89PPj4+6tatW5Xbl6Tg4OAq17t27VqXunfeeUfh4eHy9fVVo0aN1KdPH6Wnp7vUxMbGqlGjRpW28Z///KfSOnv06FGp71988YW5/dMZhqEXX3xRf/jDH+Tt7S1/f3/de++9+uGHH6p8T3V9n6dOndKsWbN03XXXyW63KyAgQA888ID279/vsq4ePXqc8+/inXfeUVRUlFq0aCFvb2+FhIRo4sSJKioqqnLMduzYoV69esnX11fNmzfX6NGjdfz4cZdam82myZMnu7RNnTq1ynmwdu1ahYaGytvbW/fcc4+OHj0qSdq2bZs6dOggb29vDRo0SAcPHqy0DZvNpmeffdal3TAMtW3bVjabTaNHjzbba/NZO1PF52Xx4sUu7RVz/XT/+te/dNtttykgIEC+vr7q0KGDZs2apbKyskrrrcn8P/Pz1KhRI910001atmyZS93Z5vTpTv97OXHihDp27Ki2bduqoKDArMnNzVVQUJB69Oih8vLycw0NLgIELEDSd999J0lq3ry5JOnw4cOSpCeffFKrVq3SokWLdPXVV6tHjx4uX6gnT55U3759NXXqVA0YMECJiYlavHixunbtqqysLJdt3Hvvvdq4caPLo1u3blX2Z8GCBUpKStK8efO0ZMkSXXHFFerbt682btxo1uzcuVM333yzMjMz9dxzz+mjjz5S//79NXbsWD311FNnfa9JSUnm9q+++upKy5csWaKoqCj5+fnpjTfe0LvvvqsmTZqoT58+Zw1Z/fr1M9dZVcCbNm2a/vznP6t9+/Z699139dZbb+no0aPq3r27du7ceda+1kZ5eblGjRolNze3SsuGDx+u+Ph49e7dWytXrtSLL76oHTt2qGvXrpUCQnXO9T4feughPfbYY4qMjNQHH3ygqVOnKikpSV27dtXPP//sUnv11VdXmg8vvviiufzbb79Vv3799PrrryspKUnx8fF69913NXDgwErbLSsrU79+/dSrVy+tXLlSo0eP1ssvv6z77ruv2vfz448/avr06ZXG7KefflL//v3lcDj03nvvqVOnTpo3b54k6YknntDkyZP1r3/9Sxs2bNDgwYMrrbdJkyZ68cUXderUKbPt448/1pEjRyrV1vSz9lt9//33io6O1ltvvaWPPvpIw4YN07PPPqvhw4e71NV2/lf83b3zzju68sorNWTIEG3atKnO/fTy8tK7776rvLw8Pfjgg5J+De7333+/DMPQ22+/XeUcx0XIAC4jixYtMiQZaWlpRllZmXH06FHjo48+Mpo3b240btzYyM3NrfJ1J0+eNMrKyoxevXoZd911l9n+5ptvGpKMV199tdrtSjJGjRpVqb1///5G69atzed79+41JBlOp9MoLi422wsLC40mTZoYvXv3Ntv69OljXHXVVUZBQYHLOkePHm14eXkZhw8fdmmfOHGiIcml/frrrzciIiLM50VFRUaTJk2MgQMHury2vLzcuPHGG41bbrml0nto0aKFMWzYMPP5559/bkgyPv/8c8MwDCMrK8twd3c3xowZ4/K6o0ePGkFBQcbgwYPNtqFDhxq+vr6VtvHee++5rNMwDCMiIsKl7/PmzTN8fX2NBx980Dj9n7aNGzcakoznnnvOZZ3Z2dmGt7e3MWHChErbq8q53ueuXbsMScbIkSNdXrdp0yZDkvH444+79P3666+v0XYNwzBOnTpllJWVGampqYYk46uvvjKXDR061JBkPP/88y6veeaZZwxJxvr16802ScaTTz5pPv/jH/9odOzY0ejevbvLWI4bN87w9vY28vPzXdokGRs3bjTb3n33XUOSkZqa6rKNYcOGGU2bNjX++9//mu133HGHMWHChLN+Fiqc7bNWlYMHDxqSjBdeeMGl/cknnzSq+3orLy83ysrKjDfffNNwc3MzPxO1mf9VbSMjI8OQZLz44otm29nm9OnO/HsxDMN45513DEnGvHnzjH/+85/GFVdcYSQnJ1e7Hlxc2IOFy1KXLl3k4eGhxo0ba8CAAQoKCtLq1asVGBho1rz00ku66aab5OXlJXd3d3l4eGjNmjXatWuXWbN69Wp5eXmZ/6dplbvvvlteXl7m88aNG2vgwIFat26dysvLdeLECa1Zs0Z33XWXfHx8dPLkSfPRr18/nThxQmlpaS7rPHbsmCTJx8fnrNvdsGGDDh8+rKFDh7qs89SpU7rjjju0ZcuWSoeoiouLXfp6pk8++UQnT57UAw884LJOLy8vRUREVLmX4vS6iu1X5+DBg3ryySf1j3/8Q61atXJZ9tFHH8lms2nIkCEu6wwKCtKNN95Y470k53qfn3/+uaRfDwmd7pZbblFISMhZ9/6dzQ8//KDo6GgFBQXJzc1NHh4eioiIkCSXOVjhzHMHo6OjXfp1pqSkJP33v//Vv/71L11xhetXwdatW9WxY0ddeeWVZltQUJDLfyXp9ttvN+tP5+XlpWHDhmn+/PmSft0b9+mnn+qhhx6qsi81+axVJSAgQE6nU//+97/1ww8/VDtf0tPTNWjQIDVt2tQczwceeEDl5eX65ptvJNVt/lfU5OXlaeHChfLw8FD37t0rbb+irqYGDx6shx56SI8++qiefvppPf7444qMjKzx61H/OMkdl6U333xTISEhcnd3V2BgoFq0aOGyfM6cORo3bpxGjBihqVOnqlmzZnJzc9M//vEPl3/0Dx06JKfTWekL6rc6/Uvs9LbS0lIdO3ZMx44d08mTJzV//nzzS+xMZx6S+umnn9SkSRPZ7fazbrficNm999571prDhw+bV1qWlZWpoKBAzZo1O+c6b7755iqXnzl2RUVF8vDwOOv6qvLoo48qKChIjzzyiKZNm1Zp+4ZhuITn01V1mPRMNXmfv/zyiyRVmkuS5HQ6zfP7auLYsWPq3r27vLy89PTTT+vaa6+Vj4+PsrOzdffdd6u4uNil3t3dXU2bNnVpq5hDFf06XUlJicaOHavY2FiFh4dXWp6bm+tybuDZOBwOSVJOTk6lZSNHjlTbtm21e/duvfTSS+rbt2+V66zpZ+1sFi9erCFDhuj3v//9WWuysrLUvXt3tWvXTs8//7yCg4Pl5eWlzZs3a9SoUeZ41nb+S3KZq97e3po/f75CQ0NdXnP6nLbb7frd736noUOH6vHHH690rtjpHnzwQS1cuFCenp4aO3ZsNaOAixEBC5elkJAQ8yrCqixZskQ9evTQwoULXdorTvSt0Lx5c61fv16nTp2yNGTl5uZW2ebp6alGjRrJw8NDbm5uiomJ0ahRo6pcR5s2bVyef/XVV+rQoUO1260IEPPnzzdP/D/T6UHl+++/N09ePtc6//Of/6h169bVbl/69Utq3bp1Lm2fffaZHnvssSrr169fryVLluiTTz6Rp6dnldu32Wz64osvqgyX1QXOCjV5nxUBJycnR1dddZXLsgMHDlQbzs702Wef6cCBA1q7dq2510pSlecwSb/uHfnll19cQlbFHDozeEm/3tPq0KFDmjlzZpXrCwwMrBTQq3Lo0CFJVf8PQevWrdW/f3/NnDlTiYmJevfdd6tcR00/a2cTGRmp/fv367vvvjP3Lr3yyit69dVXzZqVK1eqqKhI77//vssczMjIcFlXbee/JG3ZskXSryenp6amavTo0Tp58qTL5/L0OX38+HElJibq73//u3x9fRUfH1/ldoqKihQTE6Nrr71WBw8e1F//+lf997//rcGI4GJBwAKqYLPZKn3xfv3119q4caPLIai+ffvq7bff1uLFiy09TPj+++/r2WefNQ9JHT16VB9++KG6d+8uNzc3+fj4qGfPnkpPT9cNN9xQZbA43Y4dO/TDDz9o5MiR1dZ169ZNV155pXbu3OlypdfZrFy5UpKqPCRSoU+fPnJ3d9f333+ve+6555zrvOKKKyqF37Pd3LK8vFyjR4/WPffcc9bDJwMGDNCMGTP0008/VXlCdk3U5H1WHC5bsmSJy966LVu2aNeuXXriiSdqvL2KvRpnzsGXX375rK9ZunSpy16OiqvZzrw6MCsrS++8845mzZplXtRxpptuukkLFy7UoUOHzJqKwHb63q2Kw5433XRTlesZM2aMevfurWuvvfasfz81/axVx8PDQyEhIebzjz76qNI2JNfxNAzDJYRJtZ//klzm6q233qr33ntPS5cudQlYZ87p2267TYsXL9bmzZvPut4RI0YoKytLmzdv1u7du3Xvvfdq7ty5euSRR2rUL9Q/AhZQhQEDBmjq1Kl68sknFRERoT179mjKlClq06aNy3kUf/7zn7Vo0SKNGDFCe/bsUc+ePXXq1Clt2rRJISEh+tOf/lSn7bu5uSkyMlIJCQk6deqUZs6cqcLCQperA59//nndeuut6t69ux566CEFBwfr6NGj+u677/Thhx/qs88+kyRt2rRJY8aMkaenp0JDQ13OzSouLlZhYaHS09PVsWNHNWrUSPPnz9fQoUN1+PBh3XvvvQoICNChQ4f01Vdf6dChQ1q4cKFycnK0YMECzZo1S9HR0dXumQoODtaUKVP0xBNP6IcfftAdd9whf39/HTx4UJs3b5avr2+1Vz1WZ+PGjfLy8tKHH3541ppu3brpb3/7m/7yl79o69atuu222+Tr66ucnBytX79eHTp0OOu5QbV5n+3atdPf/vY3zZ8/37zqc9++feZ5YbX5Yuzatav8/f01YsQIPfnkk/Lw8NDSpUv11VdfVVnv6emp5557TseOHdPNN9+sDRs26Omnn1bfvn116623utS++eabuuGGGzRixIizbv+RRx7RSy+9pLvvvlsTJ07U9u3b9dprr0n69bDV1KlTVVhYqAkTJig8PFw9e/ascj29evXSmjVr1LJly7MeCqvpZ+23iIyMlKenp/785z9rwoQJOnHihBYuXKj8/HyXuprO/9NVfJ4q9mBlZmZWujLRMAzt3r1b0q97sD744AMdOXJEnTt3rrK/r732mpYsWaJFixbp+uuv1/XXX6/Ro0frscceU7du3XTLLbdYMi44z+r1FHvgAqu4inDLli3V1pWUlBjjx483WrZsaXh5eRk33XSTsXLlSmPo0KEuV/0ZhmEUFxcb//znP41rrrnG8PT0NJo2bWrcfvvtxoYNG8wa1fIqwpkzZxpPPfWUcdVVVxmenp5Gx44djU8++aTS6/fu3Ws8+OCDRsuWLQ0PDw+jefPmRteuXY2nn37arGndurUhqdrHme8pNTXV6N+/v9GkSRPDw8PDaNmypdG/f3/jvffeMwzDMJYtW2Zcd911xtSpU43S0lKX1555dV2FlStXGj179jT8/PwMu91utG7d2rj33nuNTz/91Kyp7VWEkozp06e71J7tCrJ///vfRufOnQ1fX1/D29vb+P3vf2888MADxtatWyvVVqjt+ywvLzdmzpxpXHvttYaHh4fRrFkzY8iQIUZ2drbLa2tyFeGGDRuM8PBww8fHx2jevLnx17/+1fjf//5nSDIWLVpk1lWM2ddff2306NHD8Pb2Npo0aWI89NBDxrFjx1zWKcmw2Wwuc7OiP6dfRWgYhpGSkmKEhIQYXl5exj333GOO64oVK4zQ0FDDy8vL6Nevn3HgwIFK26juKsEzl9fms1ZTVc2BDz/80LjxxhsNLy8vo2XLlsajjz5qrF69usq5eq75f/o2Kh52u924+uqrjfHjxxvHjx836yqu8qx4+Pj4GCEhIcYzzzxjnDp1yhyTiqsIv/76a8Pb29sYOnSoS59OnDhhhIWFGcHBwS5Xd+LiZTMMw7gQQQ7Aue3bt09t2rTRs88+q/Hjx1uyzuDgYE2ePLnS1W0V1q5dq9jYWH5jroGKjY3Vf/7zH/Mq0fNl9uzZevTRR7V3794anQAPXO64TQNwievYseNZz7WRJD8/P3Xs2PEC9ggALn2cgwVc4hITE6tdftNNN52zBgBQOxwiBAAAsBiHCAEAACxGwAIAALAYAQsAAMBinOR+gZ06dUoHDhxQ48aNq/0NKgAAcPEwDENHjx6t8e/PErAusAMHDtT45x8AAMDFJTs7u9LvjVaFgHWBNW7cWNKvf0F+fn713BsAAFAThYWFatWqlfk9fi4ErAus4rCgn58fAQsAgAampqf3cJI7AACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWMy9vjsAAFUJnriqvrtQJ/tm9K/vLgC4CLAHCwAAwGIELAAAAItxiPAS0hAPqXA4BQBwKWIPFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYrN4D1k8//aQhQ4aoadOm8vHx0R/+8Adt27bNXG4YhiZPniyn0ylvb2/16NFDO3bscFlHSUmJxowZo2bNmsnX11eDBg3S/v37XWry8/MVExMjh8Mhh8OhmJgYHTlyxKUmKytLAwcOlK+vr5o1a6axY8eqtLTUpWb79u2KiIiQt7e3WrZsqSlTpsgwDGsHBQAANGj1GrDy8/PVrVs3eXh4aPXq1dq5c6eee+45XXnllWbNrFmzNGfOHC1YsEBbtmxRUFCQIiMjdfToUbMmPj5eiYmJWr58udavX69jx45pwIABKi8vN2uio6OVkZGhpKQkJSUlKSMjQzExMeby8vJy9e/fX0VFRVq/fr2WL1+uFStWaNy4cWZNYWGhIiMj5XQ6tWXLFs2fP1+zZ8/WnDlzzu9AAQCABsVm1OPul4kTJ+rLL7/UF198UeVywzDkdDoVHx+vxx57TNKve6sCAwM1c+ZMDR8+XAUFBWrevLneeust3XfffZKkAwcOqFWrVvr444/Vp08f7dq1S+3bt1daWpo6d+4sSUpLS1N4eLh2796tdu3aafXq1RowYICys7PldDolScuXL1dsbKzy8vLk5+enhQsXatKkSTp48KDsdrskacaMGZo/f772798vm812zvdcWFgoh8OhgoIC+fn5/eYxPB13cselpCHOZ4k5DVyqavv9Xa97sD744AN16tRJ/+///T8FBASoY8eOevXVV83le/fuVW5urqKiosw2u92uiIgIbdiwQZK0bds2lZWVudQ4nU6FhoaaNRs3bpTD4TDDlSR16dJFDofDpSY0NNQMV5LUp08flZSUmIcsN27cqIiICDNcVdQcOHBA+/btq/I9lpSUqLCw0OUBAAAubfUasH744QctXLhQ11xzjT755BONGDFCY8eO1ZtvvilJys3NlSQFBga6vC4wMNBclpubK09PT/n7+1dbExAQUGn7AQEBLjVnbsff31+enp7V1lQ8r6g50/Tp083zvhwOh1q1anWOUQEAAA1dvQasU6dO6aabbtK0adPUsWNHDR8+XHFxcVq4cKFL3ZmH3gzDOOfhuDNrqqq3oqbiCOvZ+jNp0iQVFBSYj+zs7Gr7DQAAGr56DVgtWrRQ+/btXdpCQkKUlZUlSQoKCpJUee9QXl6euecoKChIpaWlys/Pr7bm4MGDlbZ/6NAhl5ozt5Ofn6+ysrJqa/Ly8iRV3stWwW63y8/Pz+UBAAAubfUasLp166Y9e/a4tH3zzTdq3bq1JKlNmzYKCgpSSkqKuby0tFSpqanq2rWrJCksLEweHh4uNTk5OcrMzDRrwsPDVVBQoM2bN5s1mzZtUkFBgUtNZmamcnJyzJrk5GTZ7XaFhYWZNevWrXO5dUNycrKcTqeCg4OtGBIAAHAJqNeA9cgjjygtLU3Tpk3Td999p2XLlumVV17RqFGjJP162C0+Pl7Tpk1TYmKiMjMzFRsbKx8fH0VHR0uSHA6Hhg0bpnHjxmnNmjVKT0/XkCFD1KFDB/Xu3VvSr3vF7rjjDsXFxSktLU1paWmKi4vTgAED1K5dO0lSVFSU2rdvr5iYGKWnp2vNmjUaP3684uLizL1O0dHRstvtio2NVWZmphITEzVt2jQlJCTU6ApCAABweXCvz43ffPPNSkxM1KRJkzRlyhS1adNG8+bN0/3332/WTJgwQcXFxRo5cqTy8/PVuXNnJScnq3HjxmbN3Llz5e7ursGDB6u4uFi9evXS4sWL5ebmZtYsXbpUY8eONa82HDRokBYsWGAud3Nz06pVqzRy5Eh169ZN3t7eio6O1uzZs80ah8OhlJQUjRo1Sp06dZK/v78SEhKUkJBwPocJAAA0MPV6H6zLEffBcsU9g3A2DXE+S8xp4FLVoO6DBQAAcCkiYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDH3+u4AAFxKgieuqu8u1Nq+Gf3ruwvAJYc9WAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFqvXgDV58mTZbDaXR1BQkLncMAxNnjxZTqdT3t7e6tGjh3bs2OGyjpKSEo0ZM0bNmjWTr6+vBg0apP3797vU5OfnKyYmRg6HQw6HQzExMTpy5IhLTVZWlgYOHChfX181a9ZMY8eOVWlpqUvN9u3bFRERIW9vb7Vs2VJTpkyRYRjWDgoAAGjw6n0P1vXXX6+cnBzzsX37dnPZrFmzNGfOHC1YsEBbtmxRUFCQIiMjdfToUbMmPj5eiYmJWr58udavX69jx45pwIABKi8vN2uio6OVkZGhpKQkJSUlKSMjQzExMeby8vJy9e/fX0VFRVq/fr2WL1+uFStWaNy4cWZNYWGhIiMj5XQ6tWXLFs2fP1+zZ8/WnDlzzvMIAQCAhqbef4vQ3d3dZa9VBcMwNG/ePD3xxBO6++67JUlvvPGGAgMDtWzZMg0fPlwFBQV6/fXX9dZbb6l3796SpCVLlqhVq1b69NNP1adPH+3atUtJSUlKS0tT586dJUmvvvqqwsPDtWfPHrVr107JycnauXOnsrOz5XQ6JUnPPfecYmNj9cwzz8jPz09Lly7ViRMntHjxYtntdoWGhuqbb77RnDlzlJCQIJvNdoFGDAAAXOzqfQ/Wt99+K6fTqTZt2uhPf/qTfvjhB0nS3r17lZubq6ioKLPWbrcrIiJCGzZskCRt27ZNZWVlLjVOp1OhoaFmzcaNG+VwOMxwJUldunSRw+FwqQkNDTXDlST16dNHJSUl2rZtm1kTEREhu93uUnPgwAHt27fvrO+vpKREhYWFLg8AAHBpq9eA1blzZ7355pv65JNP9Oqrryo3N1ddu3bVL7/8otzcXElSYGCgy2sCAwPNZbm5ufL09JS/v3+1NQEBAZW2HRAQ4FJz5nb8/f3l6elZbU3F84qaqkyfPt0898vhcKhVq1bVDwoAAGjw6jVg9e3bV/fcc486dOig3r17a9WqVZJ+PRRY4cxDb4ZhnPNw3Jk1VdVbUVNxgnt1/Zk0aZIKCgrMR3Z2drV9BwAADV+9HyI8na+vrzp06KBvv/3WPC/rzL1DeXl55p6joKAglZaWKj8/v9qagwcPVtrWoUOHXGrO3E5+fr7KysqqrcnLy5NUeS/b6ex2u/z8/FweAADg0nZRBaySkhLt2rVLLVq0UJs2bRQUFKSUlBRzeWlpqVJTU9W1a1dJUlhYmDw8PFxqcnJylJmZadaEh4eroKBAmzdvNms2bdqkgoICl5rMzEzl5OSYNcnJybLb7QoLCzNr1q1b53LrhuTkZDmdTgUHB1s/GAAAoMGq14A1fvx4paamau/evdq0aZPuvfdeFRYWaujQobLZbIqPj9e0adOUmJiozMxMxcbGysfHR9HR0ZIkh8OhYcOGady4cVqzZo3S09M1ZMgQ85CjJIWEhOiOO+5QXFyc0tLSlJaWpri4OA0YMEDt2rWTJEVFRal9+/aKiYlRenq61qxZo/HjxysuLs7c4xQdHS273a7Y2FhlZmYqMTFR06ZN4wpCAABQSb3epmH//v3685//rJ9//lnNmzdXly5dlJaWptatW0uSJkyYoOLiYo0cOVL5+fnq3LmzkpOT1bhxY3Mdc+fOlbu7uwYPHqzi4mL16tVLixcvlpubm1mzdOlSjR071rzacNCgQVqwYIG53M3NTatWrdLIkSPVrVs3eXt7Kzo6WrNnzzZrHA6HUlJSNGrUKHXq1En+/v5KSEhQQkLC+R4mAADQwNgMbkV+QRUWFsrhcKigoMDy87GCJ66ydH0Xwr4Z/eu7C7hINcT53FDxOQTOrbbf3xfVOVgAAACXAgIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGCxiyZgTZ8+XTabTfHx8WabYRiaPHmynE6nvL291aNHD+3YscPldSUlJRozZoyaNWsmX19fDRo0SPv373epyc/PV0xMjBwOhxwOh2JiYnTkyBGXmqysLA0cOFC+vr5q1qyZxo4dq9LSUpea7du3KyIiQt7e3mrZsqWmTJkiwzAsHQcAANDwXRQBa8uWLXrllVd0ww03uLTPmjVLc+bM0YIFC7RlyxYFBQUpMjJSR48eNWvi4+OVmJio5cuXa/369Tp27JgGDBig8vJysyY6OloZGRlKSkpSUlKSMjIyFBMTYy4vLy9X//79VVRUpPXr12v58uVasWKFxo0bZ9YUFhYqMjJSTqdTW7Zs0fz58zV79mzNmTPnPI4MAABoiNzruwPHjh3T/fffr1dffVVPP/202W4YhubNm6cnnnhCd999tyTpjTfeUGBgoJYtW6bhw4eroKBAr7/+ut566y317t1bkrRkyRK1atVKn376qfr06aNdu3YpKSlJaWlp6ty5syTp1VdfVXh4uPbs2aN27dopOTlZO3fuVHZ2tpxOpyTpueeeU2xsrJ555hn5+flp6dKlOnHihBYvXiy73a7Q0FB98803mjNnjhISEmSz2S7wyAEAgItVve/BGjVqlPr3728GpAp79+5Vbm6uoqKizDa73a6IiAht2LBBkrRt2zaVlZW51DidToWGhpo1GzdulMPhMMOVJHXp0kUOh8OlJjQ01AxXktSnTx+VlJRo27ZtZk1ERITsdrtLzYEDB7Rv376zvr+SkhIVFha6PAAAwKWtXgPW8uXLtW3bNk2fPr3SstzcXElSYGCgS3tgYKC5LDc3V56envL396+2JiAgoNL6AwICXGrO3I6/v788PT2rral4XlFTlenTp5vnfjkcDrVq1eqstQAA4NJQbwErOztbDz/8sJYuXSovL6+z1p156M0wjHMejjuzpqp6K2oqTnCvrj+TJk1SQUGB+cjOzq627wAAoOGrt4C1bds25eXlKSwsTO7u7nJ3d1dqaqpeeOEFubu7n3XvUF5enrksKChIpaWlys/Pr7bm4MGDlbZ/6NAhl5ozt5Ofn6+ysrJqa/Ly8iRV3st2OrvdLj8/P5cHAAC4tNVbwOrVq5e2b9+ujIwM89GpUyfdf//9ysjI0NVXX62goCClpKSYryktLVVqaqq6du0qSQoLC5OHh4dLTU5OjjIzM82a8PBwFRQUaPPmzWbNpk2bVFBQ4FKTmZmpnJwcsyY5OVl2u11hYWFmzbp161xu3ZCcnCyn06ng4GDrBwgAADRY9XYVYePGjRUaGurS5uvrq6ZNm5rt8fHxmjZtmq655hpdc801mjZtmnx8fBQdHS1JcjgcGjZsmMaNG6emTZuqSZMmGj9+vDp06GCeNB8SEqI77rhDcXFxevnllyVJf/vb3zRgwAC1a9dOkhQVFaX27dsrJiZGzz77rA4fPqzx48crLi7O3OMUHR2tp556SrGxsXr88cf17bffatq0afrnP//JFYQAAMBFvd+moToTJkxQcXGxRo4cqfz8fHXu3FnJyclq3LixWTN37ly5u7tr8ODBKi4uVq9evbR48WK5ubmZNUuXLtXYsWPNqw0HDRqkBQsWmMvd3Ny0atUqjRw5Ut26dZO3t7eio6M1e/Zss8bhcCglJUWjRo1Sp06d5O/vr4SEBCUkJFyAkQAAAA2JzeBW5BdUYWGhHA6HCgoKLD8fK3jiKkvXdyHsm9G/vruAi1RDnM8NFZ9D4Nxq+/1d7/fBAgAAuNQQsAAAACxGwAIAALAYAQsAAMBiBCwAAACLEbAAAAAsRsACAACwGAELAADAYnW+k3tRUZFSU1OVlZXl8vt8kjR27Njf3DEAAICGqk4BKz09Xf369dPx48dVVFSkJk2a6Oeff5aPj48CAgIIWAAA4LJWp0OEjzzyiAYOHKjDhw/L29tbaWlp+vHHHxUWFuby+30AAACXozoFrIyMDI0bN05ubm5yc3NTSUmJWrVqpVmzZunxxx+3uo8AAAANSp0CloeHh2w2myQpMDBQWVlZkiSHw2H+GQAA4HJVp3OwOnbsqK1bt+raa69Vz5499c9//lM///yz3nrrLXXo0MHqPgIAADQoddqDNW3aNLVo0UKSNHXqVDVt2lQPPfSQ8vLy9Morr1jaQQAAgIamTnuwOnXqZP65efPm+vjjjy3rEAAAQENXpz1Yt99+u44cOWJxVwAAAC4NdQpYa9eurXRzUQAAAPyqzj+VU3EVIQAAAFzV+ady7rrrLnl6ela57LPPPqtzhwAAABq6Oges8PBwNWrUyMq+AAAAXBLqFLBsNpseffRRBQQEWN0fAACABq9O52AZhmF1PwAAAC4ZddqD9eSTT3J4EGhAgieuqu8uAMBlpc4BS5IOHTqkPXv2yGaz6dprr1Xz5s0t7RwAAEBDVKdDhMePH9eDDz4op9Op2267Td27d5fT6dSwYcN0/Phxq/sIAADQoNQpYD3yyCNKTU3VBx98oCNHjujIkSP673//q9TUVI0bN87qPgIAADQodTpEuGLFCv3nP/9Rjx49zLZ+/frJ29tbgwcP1sKFC63qHwAAQINT50OEgYGBldoDAgI4RAgAAC57dQpY4eHhevLJJ3XixAmzrbi4WE899ZTCw8Mt6xwAAEBDVKdDhPPmzVPfvn111VVX6cYbb5TNZlNGRoa8vLz0ySefWN1HAACABqVOAatDhw769ttvtWTJEu3evVuGYehPf/qT7r//fnl7e1vdRwAAgAalTgFr3bp16tq1q+Li4qzuDwAAQINXp3OwevbsqcOHD1vdFwAAgEsCv0UIAABgsTodIpSkjRs3yt/fv8plt912W507BAAA0NDVOWDdddddVbbbbDaVl5fXuUMAAAANXZ0OEUpSbm6uTp06VelBuAIAAJe7OgUsm81mdT8AAAAuGZzkDgAAYLE6nYN16tQpq/sBAABwyajTHqzp06fr3//+d6X2f//735o5c+Zv7hQAAEBDVqeA9fLLL+u6666r1H799dfrpZde+s2dAgAAaMjqFLByc3PVokWLSu3NmzdXTk7Ob+4UAABAQ1angNWqVSt9+eWXldq//PJLOZ3O39wpAACAhqxOAeuvf/2r4uPjtWjRIv3444/68ccf9e9//1uPPPJIrX4AeuHChbrhhhvk5+cnPz8/hYeHa/Xq1eZywzA0efJkOZ1OeXt7q0ePHtqxY4fLOkpKSjRmzBg1a9ZMvr6+GjRokPbv3+9Sk5+fr5iYGDkcDjkcDsXExOjIkSMuNVlZWRo4cKB8fX3VrFkzjR07VqWlpS4127dvV0REhLy9vdWyZUtNmTKFKyoBAEAldbqKcMKECTp8+LBGjhxphhAvLy899thjmjRpUo3Xc9VVV2nGjBlq27atJOmNN97QnXfeqfT0dF1//fWaNWuW5syZo8WLF+vaa6/V008/rcjISO3Zs0eNGzeWJMXHx+vDDz/U8uXL1bRpU40bN04DBgzQtm3b5ObmJkmKjo7W/v37lZSUJEn629/+ppiYGH344YeSpPLycvXv31/NmzfX+vXr9csvv2jo0KEyDEPz58+XJBUWFioyMlI9e/bUli1b9M033yg2Nla+vr4aN25cXYYRAABcomzGb9gFc+zYMe3atUve3t665pprZLfbf3OHmjRpomeffVYPPvignE6n4uPj9dhjj0n6dW9VYGCgZs6cqeHDh6ugoEDNmzfXW2+9pfvuu0+SdODAAbVq1Uoff/yx+vTpo127dql9+/ZKS0tT586dJUlpaWkKDw/X7t271a5dO61evVoDBgxQdna2eYhz+fLlio2NVV5envz8/LRw4UJNmjRJBw8eNN/njBkzNH/+fO3fv7/GN18tLCyUw+FQQUGB/Pz8fvN4nS544ipL13ch7JvRv767cFloiHMDFw6fQ+Dcavv9XeefypGkRo0a6eabb1ZoaOhvDlfl5eVavny5ioqKFB4err179yo3N1dRUVFmjd1uV0REhDZs2CBJ2rZtm8rKylxqnE6nQkNDzZqNGzfK4XCY4UqSunTpIofD4VITGhrqcv5Ynz59VFJSom3btpk1ERERLu+zT58+OnDggPbt23fW91VSUqLCwkKXBwAAuLTV+ceet2zZovfee09ZWVmVzlV6//33a7ye7du3Kzw8XCdOnFCjRo2UmJio9u3bm+EnMDDQpT4wMFA//vijpF+vZvT09JS/v3+lmtzcXLMmICCg0nYDAgJcas7cjr+/vzw9PV1qgoODK22nYlmbNm2qfH/Tp0/XU089dc5xAAAAl4467cFavny5unXrpp07dyoxMVFlZWXauXOnPvvsMzkcjlqtq127dsrIyFBaWpoeeughDR06VDt37jSXn3nozTCMcx6OO7OmqnoraiqOrlbXn0mTJqmgoMB8ZGdnV9t3AADQ8NUpYE2bNk1z587VRx99JE9PTz3//PPatWuXBg8erN/97ne1Wpenp6fatm2rTp06afr06brxxhv1/PPPKygoSJLMPUgV8vLyzD1HQUFBKi0tVX5+frU1Bw8erLTdQ4cOudScuZ38/HyVlZVVW5OXlyep8l6209ntdvMqyYoHAAC4tNUpYH3//ffq3//XkyLtdruKiopks9n0yCOP6JVXXvlNHTIMQyUlJWrTpo2CgoKUkpJiListLVVqaqq6du0qSQoLC5OHh4dLTU5OjjIzM82a8PBwFRQUaPPmzWbNpk2bVFBQ4FKTmZnpcpPU5ORk2e12hYWFmTXr1q1zORyanJwsp9NZ6dAhAAC4vNUpYDVp0kRHjx6VJLVs2VKZmZmSpCNHjuj48eM1Xs/jjz+uL774Qvv27dP27dv1xBNPaO3atbr//vtls9kUHx+vadOmKTExUZmZmYqNjZWPj4+io6MlSQ6HQ8OGDdO4ceO0Zs0apaena8iQIerQoYN69+4tSQoJCdEdd9yhuLg4paWlKS0tTXFxcRowYIDatWsnSYqKilL79u0VExOj9PR0rVmzRuPHj1dcXJy5xyk6Olp2u12xsbHKzMxUYmKipk2bpoSEhBpfQQgAAC4PdTrJvXv37kpJSVGHDh00ePBgPfzww/rss8+UkpKiXr161Xg9Bw8eVExMjHJycuRwOHTDDTcoKSlJkZGRkn6931ZxcbFGjhyp/Px8de7cWcnJyeY9sCRp7ty5cnd31+DBg1VcXKxevXpp8eLF5j2wJGnp0qUaO3asebXhoEGDtGDBAnO5m5ubVq1apZEjR6pbt27y9vZWdHS0Zs+ebdY4HA6lpKRo1KhR6tSpk/z9/ZWQkKCEhIS6DCEAALiE1ek+WIcPH9aJEyfkdDp16tQpzZ49W+vXr1fbtm31j3/8o9JVffg/3AfLFfffuTAa4tzAhcPnEDi32n5/12oPVsU9nNzd3dWoUSPz+YgRIzRixIg6dBcAAODSU6uAdeWVV9bofKPy8vI6dwgAAKChq1XA+vzzz12eG4ahfv366bXXXlPLli0t7RgAAEBDVauAFRERUanNzc1NXbp00dVXX21ZpwAAABqy3/RbhAAAAKjsNwWsrKwsHT9+XE2bNrWqPwAAAA1erQ4RvvDCC+afDx06pGXLlun222+v9e8PAgAAXMpqFbDmzp0r6dcfN27WrJnuvPNO/f3vfz8vHQMAAGioahWw9u7de776AQAAcMmo00/lAAAuHQ3xTv/cfR4XO64iBAAAsBgBCwAAwGIELAAAAIsRsAAAACxGwAIAALAYAQsAAMBiBCwAAACLEbAAAAAsRsACAACwGAELAADAYgQsAAAAixGwAAAALEbAAgAAsBgBCwAAwGIELAAAAIsRsAAAACxGwAIAALAYAQsAAMBiBCwAAACLEbAAAAAsRsACAACwGAELAADAYgQsAAAAixGwAAAALEbAAgAAsBgBCwAAwGIELAAAAIsRsAAAACxGwAIAALAYAQsAAMBiBCwAAACLEbAAAAAsRsACAACwGAELAADAYgQsAAAAi9VrwJo+fbpuvvlmNW7cWAEBAfrjH/+oPXv2uNQYhqHJkyfL6XTK29tbPXr00I4dO1xqSkpKNGbMGDVr1ky+vr4aNGiQ9u/f71KTn5+vmJgYORwOORwOxcTE6MiRIy41WVlZGjhwoHx9fdWsWTONHTtWpaWlLjXbt29XRESEvL291bJlS02ZMkWGYVg3KAAAoMGr14CVmpqqUaNGKS0tTSkpKTp58qSioqJUVFRk1syaNUtz5szRggULtGXLFgUFBSkyMlJHjx41a+Lj45WYmKjly5dr/fr1OnbsmAYMGKDy8nKzJjo6WhkZGUpKSlJSUpIyMjIUExNjLi8vL1f//v1VVFSk9evXa/ny5VqxYoXGjRtn1hQWFioyMlJOp1NbtmzR/PnzNXv2bM2ZM+c8jxQAAGhIbMZFtPvl0KFDCggIUGpqqm677TYZhiGn06n4+Hg99thjkn7dWxUYGKiZM2dq+PDhKigoUPPmzfXWW2/pvvvukyQdOHBArVq10scff6w+ffpo165dat++vdLS0tS5c2dJUlpamsLDw7V79261a9dOq1ev1oABA5SdnS2n0ylJWr58uWJjY5WXlyc/Pz8tXLhQkyZN0sGDB2W32yVJM2bM0Pz587V//37ZbLZzvsfCwkI5HA4VFBTIz8/P0vELnrjK0vVdCPtm9K/vLlwWGuLcAKrDvx240Gr7/X1RnYNVUFAgSWrSpIkkae/evcrNzVVUVJRZY7fbFRERoQ0bNkiStm3bprKyMpcap9Op0NBQs2bjxo1yOBxmuJKkLl26yOFwuNSEhoaa4UqS+vTpo5KSEm3bts2siYiIMMNVRc2BAwe0b9++Kt9TSUmJCgsLXR4AAODSdtEELMMwlJCQoFtvvVWhoaGSpNzcXElSYGCgS21gYKC5LDc3V56envL396+2JiAgoNI2AwICXGrO3I6/v788PT2rral4XlFzpunTp5vnfTkcDrVq1eocIwEAABq6iyZgjR49Wl9//bXefvvtSsvOPPRmGMY5D8edWVNVvRU1FUdYz9afSZMmqaCgwHxkZ2dX228AANDwXRQBa8yYMfrggw/0+eef66qrrjLbg4KCJFXeO5SXl2fuOQoKClJpaany8/OrrTl48GCl7R46dMil5szt5Ofnq6ysrNqavLw8SZX3slWw2+3y8/NzeQAAgEtbvQYswzA0evRovf/++/rss8/Upk0bl+Vt2rRRUFCQUlJSzLbS0lKlpqaqa9eukqSwsDB5eHi41OTk5CgzM9OsCQ8PV0FBgTZv3mzWbNq0SQUFBS41mZmZysnJMWuSk5Nlt9sVFhZm1qxbt87l1g3JyclyOp0KDg62aFQAAEBDV68Ba9SoUVqyZImWLVumxo0bKzc3V7m5uSouLpb062G3+Ph4TZs2TYmJicrMzFRsbKx8fHwUHR0tSXI4HBo2bJjGjRunNWvWKD09XUOGDFGHDh3Uu3dvSVJISIjuuOMOxcXFKS0tTWlpaYqLi9OAAQPUrl07SVJUVJTat2+vmJgYpaena82aNRo/frzi4uLMvU7R0dGy2+2KjY1VZmamEhMTNW3aNCUkJNToCkIAAHB5cK/PjS9cuFCS1KNHD5f2RYsWKTY2VpI0YcIEFRcXa+TIkcrPz1fnzp2VnJysxo0bm/Vz586Vu7u7Bg8erOLiYvXq1UuLFy+Wm5ubWbN06VKNHTvWvNpw0KBBWrBggbnczc1Nq1at0siRI9WtWzd5e3srOjpas2fPNmscDodSUlI0atQoderUSf7+/kpISFBCQoLVQwMAABqwi+o+WJcD7oPlinvZXBgNcW4A1eHfDlxoDfo+WAAAAJcCAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWc6/vDgANTfDEVfXdBQDARY49WAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWq9eAtW7dOg0cOFBOp1M2m00rV650WW4YhiZPniyn0ylvb2/16NFDO3bscKkpKSnRmDFj1KxZM/n6+mrQoEHav3+/S01+fr5iYmLkcDjkcDgUExOjI0eOuNRkZWVp4MCB8vX1VbNmzTR27FiVlpa61Gzfvl0RERHy9vZWy5YtNWXKFBmGYdl4AACAS0O9BqyioiLdeOONWrBgQZXLZ82apTlz5mjBggXasmWLgoKCFBkZqaNHj5o18fHxSkxM1PLly7V+/XodO3ZMAwYMUHl5uVkTHR2tjIwMJSUlKSkpSRkZGYqJiTGXl5eXq3///ioqKtL69eu1fPlyrVixQuPGjTNrCgsLFRkZKafTqS1btmj+/PmaPXu25syZcx5GBgAANGTu9bnxvn37qm/fvlUuMwxD8+bN0xNPPKG7775bkvTGG28oMDBQy5Yt0/Dhw1VQUKDXX39db731lnr37i1JWrJkiVq1aqVPP/1Uffr00a5du5SUlKS0tDR17txZkvTqq68qPDxce/bsUbt27ZScnKydO3cqOztbTqdTkvTcc88pNjZWzzzzjPz8/LR06VKdOHFCixcvlt1uV2hoqL755hvNmTNHCQkJstlsF2DEAABAQ3DRnoO1d+9e5ebmKioqymyz2+2KiIjQhg0bJEnbtm1TWVmZS43T6VRoaKhZs3HjRjkcDjNcSVKXLl3kcDhcakJDQ81wJUl9+vRRSUmJtm3bZtZERETIbre71Bw4cED79u076/soKSlRYWGhywMAAFzaLtqAlZubK0kKDAx0aQ8MDDSX5ebmytPTU/7+/tXWBAQEVFp/QECAS82Z2/H395enp2e1NRXPK2qqMn36dPPcL4fDoVatWlX/xgEAQIN30QasCmceejMM45yH486sqareipqKE9yr68+kSZNUUFBgPrKzs6vtOwAAaPgu2oAVFBQkqfLeoby8PHPPUVBQkEpLS5Wfn19tzcGDByut/9ChQy41Z24nPz9fZWVl1dbk5eVJqryX7XR2u11+fn4uDwAAcGmr15Pcq9OmTRsFBQUpJSVFHTt2lCSVlpYqNTVVM2fOlCSFhYXJw8NDKSkpGjx4sCQpJydHmZmZmjVrliQpPDxcBQUF2rx5s2655RZJ0qZNm1RQUKCuXbuaNc8884xycnLUokULSVJycrLsdrvCwsLMmscff1ylpaXy9PQ0a5xOp4KDgy/MoAAAJEnBE1fVdxdqbd+M/vXdBVxA9boH69ixY8rIyFBGRoakX09sz8jIUFZWlmw2m+Lj4zVt2jQlJiYqMzNTsbGx8vHxUXR0tCTJ4XBo2LBhGjdunNasWaP09HQNGTJEHTp0MK8qDAkJ0R133KG4uDilpaUpLS1NcXFxGjBggNq1aydJioqKUvv27RUTE6P09HStWbNG48ePV1xcnLnHKTo6Wna7XbGxscrMzFRiYqKmTZvGFYQAAKCSet2DtXXrVvXs2dN8npCQIEkaOnSoFi9erAkTJqi4uFgjR45Ufn6+OnfurOTkZDVu3Nh8zdy5c+Xu7q7BgweruLhYvXr10uLFi+Xm5mbWLF26VGPHjjWvNhw0aJDLvbfc3Ny0atUqjRw5Ut26dZO3t7eio6M1e/Zss8bhcCglJUWjRo1Sp06d5O/vr4SEBLPPAAAAFWwGtyK/oAoLC+VwOFRQUGD5+VjsMr8wGuI4A6h/DfHfO/yf2n5/X7TnYAEAcClpiP9zRiisu4v2KkIAAICGioAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDFu0wAAAKrErSXqjj1YAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNgAQAAWIyABQAAYDECFgAAgMUIWAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWAACAxQhYAAAAFiNg1cGLL76oNm3ayMvLS2FhYfriiy/qu0sAAOAi4l7fHWho3nnnHcXHx+vFF19Ut27d9PLLL6tv377auXOnfve739V39xqc4Imr6rsLAABYjj1YtTRnzhwNGzZMf/3rXxUSEqJ58+apVatWWrhwYX13DQAAXCQIWLVQWlqqbdu2KSoqyqU9KipKGzZsqKdeAQCAiw2HCGvh559/Vnl5uQIDA13aAwMDlZubW+VrSkpKVFJSYj4vKCiQJBUWFlrev1Mlxy1fJwAADcn5+H49fb2GYdSonoBVBzabzeW5YRiV2ipMnz5dTz31VKX2Vq1anZe+AQBwOXPMO7/rP3r0qBwOxznrCFi10KxZM7m5uVXaW5WXl1dpr1aFSZMmKSEhwXx+6tQpHT58WE2bNj1rKKuLwsJCtWrVStnZ2fLz87NsvZc6xq32GLPaY8zqhnGrPcasbmoyboZh6OjRo3I6nTVaJwGrFjw9PRUWFqaUlBTdddddZntKSoruvPPOKl9jt9tlt9td2q688srz1kc/Pz8+VHXAuNUeY1Z7jFndMG61x5jVzbnGrSZ7rioQsGopISFBMTEx6tSpk8LDw/XKK68oKytLI0aMqO+uAQCAiwQBq5buu+8+/fLLL5oyZYpycnIUGhqqjz/+WK1bt67vrgEAgIsEAasORo4cqZEjR9Z3N1zY7XY9+eSTlQ5HonqMW+0xZrXHmNUN41Z7jFndnI9xsxk1vd4QAAAANcKNRgEAACxGwAIAALAYAQsAAMBiBCwAAACLEbAakBdffFFt2rSRl5eXwsLC9MUXX1Rbn5qaqrCwMHl5eenqq6/WSy+9dIF6evGozZitXbtWNput0mP37t0XsMf1b926dRo4cKCcTqdsNptWrlx5ztdc7nOttmPGXPv1Z8RuvvlmNW7cWAEBAfrjH/+oPXv2nPN1l/Ncq8uYMdekhQsX6oYbbjBvIhoeHq7Vq1dX+xor5hkBq4F45513FB8fryeeeELp6enq3r27+vbtq6ysrCrr9+7dq379+ql79+5KT0/X448/rrFjx2rFihUXuOf1p7ZjVmHPnj3KyckxH9dcc80F6vHFoaioSDfeeKMWLFhQo3rmWu3HrMLlPNdSU1M1atQopaWlKSUlRSdPnlRUVJSKiorO+prLfa7VZcwqXM5z7aqrrtKMGTO0detWbd26VbfffrvuvPNO7dixo8p6y+aZgQbhlltuMUaMGOHSdt111xkTJ06ssn7ChAnGdddd59I2fPhwo0uXLuetjxeb2o7Z559/bkgy8vPzL0DvGgZJRmJiYrU1zDVXNRkz5lpleXl5hiQjNTX1rDXMNVc1GTPmWtX8/f2N1157rcplVs0z9mA1AKWlpdq2bZuioqJc2qOiorRhw4YqX7Nx48ZK9X369NHWrVtVVlZ23vp6sajLmFXo2LGjWrRooV69eunzzz8/n928JFzuc+23YK79n4KCAklSkyZNzlrDXHNVkzGrwFz7VXl5uZYvX66ioiKFh4dXWWPVPCNgNQA///yzysvLFRgY6NIeGBio3NzcKl+Tm5tbZf3Jkyf1888/n7e+XizqMmYtWrTQK6+8ohUrVuj9999Xu3bt1KtXL61bt+5CdLnButznWl0w11wZhqGEhATdeuutCg0NPWsdc+3/1HTMmGu/2r59uxo1aiS73a4RI0YoMTFR7du3r7LWqnnGT+U0IDabzeW5YRiV2s5VX1X7paw2Y9auXTu1a9fOfB4eHq7s7GzNnj1bt91223ntZ0PHXKsd5pqr0aNH6+uvv9b69evPWctc+1VNx4y59qt27dopIyNDR44c0YoVKzR06FClpqaeNWRZMc/Yg9UANGvWTG5ubpX2vOTl5VVK2RWCgoKqrHd3d1fTpk3PW18vFnUZs6p06dJF3377rdXdu6Rc7nPNKpfrXBszZow++OADff7557rqqquqrWWu/ao2Y1aVy3GueXp6qm3bturUqZOmT5+uG2+8Uc8//3yVtVbNMwJWA+Dp6amwsDClpKS4tKekpKhr165VviY8PLxSfXJysjp16iQPD4/z1teLRV3GrCrp6elq0aKF1d27pFzuc80ql9tcMwxDo0eP1vvvv6/PPvtMbdq0OedrLve5Vpcxq8rlNteqYhiGSkpKqlxm2Tyr3Xn3qC/Lly83PDw8jNdff93YuXOnER8fb/j6+hr79u0zDMMwJk6caMTExJj1P/zwg+Hj42M88sgjxs6dO43XX3/d8PDwMP7zn//U11u44Go7ZnPnzjUSExONb775xsjMzDQmTpxoSDJWrFhRX2+hXhw9etRIT0830tPTDUnGnDlzjPT0dOPHH380DIO5VpXajhlzzTAeeughw+FwGGvXrjVycnLMx/Hjx80a5pqruowZc80wJk2aZKxbt87Yu3ev8fXXXxuPP/64ccUVVxjJycmGYZy/eUbAakD+9a9/Ga1btzY8PT2Nm266yeXS3KFDhxoREREu9WvXrjU6duxoeHp6GsHBwcbChQsvcI/rX23GbObMmcbvf/97w8vLy/D39zduvfVWY9WqVfXQ6/pVcVn3mY+hQ4cahsFcq0ptx4y5ZlQ5XpKMRYsWmTXMNVd1GTPmmmE8+OCD5vdA8+bNjV69epnhyjDO3zyzGcb/f+YWAAAALME5WAAAABYjYAEAAFiMgAUAAGAxAhYAAIDFCFgAAAAWI2ABAABYjIAFAABgMQIWgCr16NFD8fHx9d2NSkpLS9W2bVt9+eWX1dbFxsbqj3/844XpFGrl5ptv1vvvv1/f3QDOKwIWgIvC+++/r8jISDVv3lx+fn4KDw/XJ598UqnulVdeUevWrdWtWzdJ0r59+2Sz2ZSRkeFS9/zzz2vx4sUXoOcNw4UKzOvWrdPAgQPldDpls9m0cuXKSjX/+Mc/NHHiRJ06deq89weoLwQsABeFdevWKTIyUh9//LG2bdumnj17auDAgUpPT3epmz9/vv7617+ec30Oh0NXXnnleert5SM4OFhr166tcX1RUZFuvPFGLViw4Kw1/fv3V0FBQZUBGrhUELAA1Eh+fr4eeOAB+fv7y8fHR3379tW3337rUvPqq6+qVatW8vHx0V133aU5c+bUOOTMmzdPEyZM0M0336xrrrlG06ZN0zXXXKMPP/zQrPnf//6n7777Tv379zfb2rRpI0nq2LGjbDabevToIanyIcIePXpo9OjRGj16tK688ko1bdpUf//731XTXwtbsmSJOnXqpMaNGysoKEjR0dHKy8szl69du1Y2m02ffPKJOnbsKG9vb91+++3Ky8vT6tWrFRISIj8/P/35z3/W8ePHzdeVlJRo7NixCggIkJeXl2699VZt2bLFXL548eJKY7hy5UrZbDbz+eTJk/WHP/xBb731loKDg+VwOPSnP/1JR48eNcciNTVVzz//vGw2m2w2m/bt21ej911bffv21dNPP6277777rDVubm7q16+f3n777fPSB+BiQMACUCOxsbHaunWrPvjgA23cuFGGYahfv34qKyuTJH355ZcaMWKEHn74YWVkZCgyMlLPPPNMnbd36tQpHT16VE2aNDHb1q1bp2uvvVZ+fn5m2+bNmyVJn376qXJycqo9t+eNN96Qu7u7Nm3apBdeeEFz587Va6+9VqP+lJaWaurUqfrqq6+0cuVK7d27V7GxsZXqJk+erAULFmjDhg3Kzs7W4MGDNW/ePC1btkyrVq1SSkqK5s+fb9ZPmDBBK1as0BtvvKH//e9/atu2rfr06aPDhw/XqF8Vvv/+e61cuVIfffSRPvroI6WmpmrGjBmSfj1cGh4erri4OOXk5CgnJ0etWrWq1fqtdsstt+iLL76o1z4A59Vv+YVqAJeuiIgI4+GHHzYMwzC++eYbQ5Lx5Zdfmst//vlnw9vb23j33XcNwzCM++67z+jfv7/LOu6//37D4XDUafuzZs0ymjRpYhw8eNBse/jhh43bb7/dpW7v3r2GJCM9Pd2lfejQocadd97p8n5CQkKMU6dOmW2PPfaYERISUqf+bd682ZBkHD161DAMw/j8888NScann35q1kyfPt2QZHz//fdm2/Dhw40+ffoYhmEYx44dMzw8PIylS5eay0tLSw2n02nMmjXLMAzDWLRoUaUxTExMNE7/5/vJJ580fHx8jMLCQrPt0UcfNTp37uzy/iv+PmujdevWxueff17r1xmGYUgyEhMTq1z23//+17jiiiuM8vLyOq0buNixBwvAOe3atUvu7u7q3Lmz2da0aVO1a9dOu3btkiTt2bNHt9xyi8vrznxeU2+//bYmT56sd955RwEBAWZ7cXGxvLy86rROSerSpYvLobXw8HB9++23Ki8vP+dr09PTdeedd6p169Zq3LixeSgyKyvLpe6GG24w/xwYGCgfHx9dffXVLm0Vhxa///57lZWVmSfsS5KHh4duueUWc1xrKjg4WI0bNzaft2jRwuUQZk2NGDFCjRo1Mh9ZWVnq27dvpbbfytvbW6dOnVJJSclvXhdwMSJgATgn4yznKRmGYQaW0/98rtdV55133tGwYcP07rvvqnfv3i7LmjVrpvz8/Fqv87cqKipSVFSUGjVqpCVLlmjLli1KTEyU9Ouhw9N5eHiYf7bZbC7PK9oqrp6rGJ+qxq2i7Yorrqg0jhWHZc+23TO3UxtTpkxRRkaG+XA6nXrttdcqtf1Whw8flo+Pj7y9vX/zuoCLEQELwDm1b99eJ0+e1KZNm8y2X375Rd98841CQkIkSdddd515PlSFrVu31mo7b7/9tmJjY7Vs2TKXE9krdOzYUbt373YJHJ6enpJUo71QaWlplZ5fc801cnNzq/Z1u3fv1s8//6wZM2aoe/fuuu666+q0d+hMbdu2laenp9avX2+2lZWVaevWrea4Nm/eXEePHlVRUZFZc+YtKWrC09OzRmMUEBCgtm3bmg93d3e1bNmyUttvlZmZqZtuuuk3rwe4WBGwAJzTNddcozvvvFNxcXFav369vvrqKw0ZMkQtW7bUnXfeKUkaM2aMPv74Y82ZM0fffvutXn75Za1evbrS3pmzefvtt/XAAw/oueeeU5cuXZSbm6vc3FwVFBSYNT179lRRUZF27NhhtgUEBMjb21tJSUk6ePCgS/2ZsrOzlZCQoD179ujtt9/W/Pnz9fDDD5+zb7/73e/k6emp+fPn64cfftAHH3ygqVOn1uh9VcfX11cPPfSQHn30USUlJWnnzp2Ki4vT8ePHNWzYMElS586d5ePjo8cff1zfffedli1bVqf7ewUHB2vTpk3at2+ffv755/N2D6pjx46Ze7okae/evcrIyKh0WPGLL75QVFTUeekDcDEgYAGokUWLFiksLEwDBgxQeHi4DMPQxx9/bB6a6tatm1566SXNmTNHN954o5KSkvTII4/U+Jypl19+WSdPntSoUaPUokUL83F6AGratKnuvvtuLV261Gxzd3fXCy+8oJdffllOp9MMfFV54IEHVFxcrFtuuUWjRo3SmDFj9Le//e2cfWvevLkWL16s9957T+3bt9eMGTM0e/bsGr2vc5kxY4buuecexcTE6KabbtJ3332nTz75RP7+/pKkJk2aaMmSJfr444/VoUMH8/y02ho/frzc3NzUvn17NW/e3JLzqKqydetWdezYUR07dpQkJSQkqGPHjvrnP/9p1vz000/asGGD/vKXv5yXPgAXA5tRl5MkAKAG4uLitHv3bksvx9++fbt69+6t7777zuWk7nPp0aOH/vCHP2jevHmW9QV18+ijj6qgoECvvPJKfXcFOG/YgwXAMrNnz9ZXX32l7777TvPnz9cbb7yhoUOHWrqNDh06aNasWeftRpk4/wICAiw5xApczNiDBcAygwcP1tq1a3X06FFdffXVGjNmjEaMGCFJuv766/Xjjz9W+bqXX35Z999//3ntW3V7sL744gv17dv3rK89duzYeewZgEsRAQvABfHjjz9WeXsB6dd7Q9XmcJ/ViouL9dNPP511edu2bS9gbwBcCghYAAAAFuMcLAAAAIsRsAAAACxGwAIAALAYAQsAAMBiBCwAAACLEbAAAAAsRsACAACwGAELAADAYv8fimg2CTANpQoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path_in = 'data.parquet'\n",
    "# path_out = sys.argv[2]\n",
    "df = pd.read_parquet(path_in)\n",
    "\n",
    "print('Length of dataframe is {}'.format(len(df)))\n",
    "\n",
    "print('Column names')\n",
    "print(df.columns)\n",
    "\n",
    "print('Column types')\n",
    "print(df.dtypes)\n",
    "\n",
    "print('Dropping total_amount and tolls_amount (they include the target)')\n",
    "df.drop(columns=['total_amount', 'tolls_amount'], inplace=True)\n",
    "\n",
    "for col in df.columns:\n",
    "    print('#unique in {} is {}'.format(col, df[col].nunique()))\n",
    "\n",
    "for col in df.columns:\n",
    "    print('percentage of NAs in {} is {:.1f}%'.format(col, 100. * df[col].isna().sum() / len(df)))\n",
    "\n",
    "print('Droping rows with missing values')\n",
    "df.dropna(inplace=True)\n",
    "print('Now length of dataframe is {}'.format(len(df)))\n",
    "\n",
    "print('Convert Store_and_fwd_flag to number')\n",
    "df.store_and_fwd_flag = (df.store_and_fwd_flag == 'Y').astype('int64')\n",
    "\n",
    "for col in df.columns:\n",
    "    print('Droping rows with anomalous values of {}'.format(col))\n",
    "    lower_bound = df[col].quantile(0.005)\n",
    "    upper_bound = df[col].quantile(0.995)\n",
    "\n",
    "    cond = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "    df.drop(df[cond].index, inplace=True)\n",
    "\n",
    "    print('Now length of dataframe is {}'.format(len(df)))\n",
    "\n",
    "target = np.log(df.tip_amount + 1.)\n",
    "plt.hist(target)\n",
    "plt.title('Распределение логарифма чаевых')\n",
    "plt.xlabel('log_2(tip_amount + 1)')\n",
    "plt.ylabel('Частота')\n",
    "plt.savefig('target_dist.png')\n",
    "\n",
    "print('Dropping tip_amount from dataframe')\n",
    "df.drop(columns=['tip_amount'], inplace=True)\n",
    "\n",
    "df['duration'] = (df.tpep_dropoff_datetime - df.tpep_pickup_datetime) / datetime.timedelta(minutes=1)\n",
    "print('Dropping tpep_pickup_datetime and tpep_dropoff_datetime')\n",
    "pickup_day = df.tpep_pickup_datetime.dt.day\n",
    "df.drop(columns=['tpep_pickup_datetime', 'tpep_dropoff_datetime'], inplace=True)\n",
    "\n",
    "cols_to_drop = []\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() < 300:\n",
    "        print('Variable {} is categorial, doing one hot encoding of it'.format(col))\n",
    "        cols_to_drop.append(col)\n",
    "\n",
    "        for value in df[col].unique():\n",
    "            new_col_name = '{}=={}'.format(col, value)\n",
    "            new_col_val = (df[col] == value).astype('int64')\n",
    "            c = target.corr(new_col_val)\n",
    "            if (not np.isnan(c)) and abs(c) > 0.015:\n",
    "                df[new_col_name] = new_col_val  \n",
    "\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "print('Correlations with target:')\n",
    "for col in df.columns:\n",
    "    c = target.corr(df[col])\n",
    "    print('{} {:.2f}'.format(col, c))\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['target'] = target\n",
    "\n",
    "for i, col in enumerate(df.columns):\n",
    "    mu = df[col].mean()\n",
    "    sigma = df[col].std()\n",
    "    result[str(i)] = (df[col] - mu) / sigma\n",
    "\n",
    "# df_train1 = result[pickup_day < 12]\n",
    "# df_train2 = result[(pickup_day >= 12) & (pickup_day < 23)]\n",
    "# df_test = result[(pickup_day >= 23) & (pickup_day < 26)]\n",
    "# print(\"Divide data to train and test by 23.01\")\n",
    "# print(f\"Train size: {df_train1.shape[0] + df_train2.shape[0]}\")\n",
    "# print(f\"Test size: {df_test.shape[0]}\")\n",
    "\n",
    "# df_train1.to_csv(\"data_train1.csv\")\n",
    "# df_train2.to_csv(\"data_train2.csv\")\n",
    "# df_test.to_csv(\"data_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train1 = result[pickup_day == 30].iloc[:25000]\n",
    "# df_train2 = result[(pickup_day >= 12) & (pickup_day < 23)]\n",
    "# # df_test = result[(pickup_day >= 23) & (pickup_day < 26)]\n",
    "df_test = result[(pickup_day == 31)].iloc[:25000]\n",
    "# print(\"Divide data to train and test by 23.01\")\n",
    "# print(f\"Train size: {df_train1.shape[0] + df_train2.shape[0]}\")\n",
    "# print(f\"Test size: {df_test.shape[0]}\")\n",
    "\n",
    "# df_train1.to_excel(\"data_train1.xlsx\")\n",
    "# df_train2.to_csv(\"data_train2.csv\")\n",
    "df_test.to_excel(\"data_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610975"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df.tpep_pickup_datetime.dt.day < 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.15\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df_train1 = pd.read_parquet(\"data_train1.parquet\")\n",
    "df_train2 = pd.read_parquet(\"data_train2.parquet\")\n",
    "df_test = pd.read_parquet(\"data_test.parquet\")\n",
    "\n",
    "df_train = pd.concat([df_train1, df_train2])\n",
    "df_train.shape[0]\n",
    "\n",
    "y_train = df_train.target\n",
    "X_train = df_train.drop(columns=['target'])\n",
    "y_test = df_test.target\n",
    "X_test = df_test.drop(columns=['target'])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('MSE: {:.2f}'.format(mean_squared_error(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12840412798530823"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model = CatBoostRegressor()\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13051303388396024"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model = CatBoostRegressor(iterations=10)\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-31 18:44:45,615]\u001b[0m A new study created in memory with name: no-name-56abf9b7-4a52-4de0-a211-a10d19b6abec\u001b[0m\n",
      "C:\\Users\\world\\AppData\\Local\\Temp\\ipykernel_74296\\3077671878.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
      "\u001b[32m[I 2023-05-31 18:44:55,415]\u001b[0m Trial 0 finished with value: 0.4558212739788796 and parameters: {'learning_rate': 0.0011398552388028624, 'depth': 3}. Best is trial 0 with value: 0.4558212739788796.\u001b[0m\n",
      "C:\\Users\\world\\AppData\\Local\\Temp\\ipykernel_74296\\3077671878.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
      "\u001b[32m[I 2023-05-31 18:45:25,171]\u001b[0m Trial 1 finished with value: 0.2745207030468253 and parameters: {'learning_rate': 0.005275324211165609, 'depth': 10}. Best is trial 1 with value: 0.2745207030468253.\u001b[0m\n",
      "C:\\Users\\world\\AppData\\Local\\Temp\\ipykernel_74296\\3077671878.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
      "\u001b[32m[I 2023-05-31 18:45:36,097]\u001b[0m Trial 2 finished with value: 0.35963465532401223 and parameters: {'learning_rate': 0.003033859643299722, 'depth': 3}. Best is trial 1 with value: 0.2745207030468253.\u001b[0m\n",
      "C:\\Users\\world\\AppData\\Local\\Temp\\ipykernel_74296\\3077671878.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
      "\u001b[32m[I 2023-05-31 18:46:13,621]\u001b[0m Trial 3 finished with value: 0.12947308007354488 and parameters: {'learning_rate': 0.044186512748163154, 'depth': 10}. Best is trial 3 with value: 0.12947308007354488.\u001b[0m\n",
      "C:\\Users\\world\\AppData\\Local\\Temp\\ipykernel_74296\\3077671878.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
      "\u001b[32m[I 2023-05-31 18:46:29,051]\u001b[0m Trial 4 finished with value: 0.12934236433167767 and parameters: {'learning_rate': 0.08617103393610565, 'depth': 6}. Best is trial 4 with value: 0.12934236433167767.\u001b[0m\n",
      "C:\\Users\\world\\AppData\\Local\\Temp\\ipykernel_74296\\3077671878.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
      "\u001b[32m[I 2023-05-31 18:46:43,475]\u001b[0m Trial 5 finished with value: 0.489793627984174 and parameters: {'learning_rate': 0.0005890557820998436, 'depth': 6}. Best is trial 4 with value: 0.12934236433167767.\u001b[0m\n",
      "C:\\Users\\world\\AppData\\Local\\Temp\\ipykernel_74296\\3077671878.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
      "\u001b[32m[I 2023-05-31 18:47:02,740]\u001b[0m Trial 6 finished with value: 0.5304335123932663 and parameters: {'learning_rate': 3.377045572655029e-05, 'depth': 9}. Best is trial 4 with value: 0.12934236433167767.\u001b[0m\n",
      "C:\\Users\\world\\AppData\\Local\\Temp\\ipykernel_74296\\3077671878.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
      "\u001b[32m[I 2023-05-31 18:47:18,619]\u001b[0m Trial 7 finished with value: 0.34485761704202716 and parameters: {'learning_rate': 0.003276252166555874, 'depth': 6}. Best is trial 4 with value: 0.12934236433167767.\u001b[0m\n",
      "C:\\Users\\world\\AppData\\Local\\Temp\\ipykernel_74296\\3077671878.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
      "\u001b[32m[I 2023-05-31 18:47:37,077]\u001b[0m Trial 8 finished with value: 0.12950984446260114 and parameters: {'learning_rate': 0.050364693769191234, 'depth': 8}. Best is trial 4 with value: 0.12934236433167767.\u001b[0m\n",
      "C:\\Users\\world\\AppData\\Local\\Temp\\ipykernel_74296\\3077671878.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
      "\u001b[32m[I 2023-05-31 18:48:58,165]\u001b[0m Trial 9 finished with value: 0.2523489543055548 and parameters: {'learning_rate': 0.006105292848132666, 'depth': 15}. Best is trial 4 with value: 0.12934236433167767.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mse: 0.12934236433167767\n",
      "Best params: {'learning_rate': 0.08617103393610565, 'depth': 6}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        # 'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.00001, 0.1),\n",
    "        # 'num_leaves' : trial.suggest_int('num_leaves', 20, 60, 4),\n",
    "        # 'min_child_samples':  trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32]),\n",
    "        'depth': trial.suggest_int('depth', 3, 15),\n",
    "        'random_state': 42,\n",
    "        'iterations': 100,\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    res = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print('Best mse:', study.best_value)\n",
    "print('Best params:', study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "y_train_0 = (y_train == 0) * 1\n",
    "model_detect_0 = LogisticRegression()\n",
    "model_detect_0.fit(X_train, y_train_0)\n",
    "\n",
    "not_0 = (y_train != 0)\n",
    "y_train_not_0 = y_train[not_0]\n",
    "X_train_not_0 = X_train[not_0]\n",
    "model_regr = LinearRegression()\n",
    "model_regr.fit(X_train_not_0, y_train_not_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2102214</th>\n",
       "      <td>-0.575605</td>\n",
       "      <td>-0.804541</td>\n",
       "      <td>-0.299616</td>\n",
       "      <td>0.603465</td>\n",
       "      <td>-0.603465</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>-0.132536</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>-0.186377</td>\n",
       "      <td>-0.167934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.599105</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>-0.084681</td>\n",
       "      <td>-0.088969</td>\n",
       "      <td>-0.251814</td>\n",
       "      <td>0.251814</td>\n",
       "      <td>0.288803</td>\n",
       "      <td>-0.288803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103001</th>\n",
       "      <td>0.911788</td>\n",
       "      <td>0.772445</td>\n",
       "      <td>0.069083</td>\n",
       "      <td>-1.657097</td>\n",
       "      <td>1.657097</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>7.545127</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>-0.186377</td>\n",
       "      <td>-0.167934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.599105</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>-0.084681</td>\n",
       "      <td>-0.088969</td>\n",
       "      <td>3.971182</td>\n",
       "      <td>-3.971182</td>\n",
       "      <td>-3.462571</td>\n",
       "      <td>3.462571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103003</th>\n",
       "      <td>2.300907</td>\n",
       "      <td>2.250869</td>\n",
       "      <td>0.355848</td>\n",
       "      <td>0.603465</td>\n",
       "      <td>-0.603465</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>-0.132536</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>-0.186377</td>\n",
       "      <td>-0.167934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.599105</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>-0.084681</td>\n",
       "      <td>11.239804</td>\n",
       "      <td>3.971182</td>\n",
       "      <td>-3.971182</td>\n",
       "      <td>-3.462571</td>\n",
       "      <td>3.462571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103009</th>\n",
       "      <td>-0.429522</td>\n",
       "      <td>-0.656699</td>\n",
       "      <td>-0.270073</td>\n",
       "      <td>0.603465</td>\n",
       "      <td>-0.603465</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>-0.132536</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>-0.186377</td>\n",
       "      <td>-0.167934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.599105</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>-0.084681</td>\n",
       "      <td>-0.088969</td>\n",
       "      <td>-0.251814</td>\n",
       "      <td>0.251814</td>\n",
       "      <td>0.288803</td>\n",
       "      <td>-0.288803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103013</th>\n",
       "      <td>1.137553</td>\n",
       "      <td>0.969568</td>\n",
       "      <td>0.083263</td>\n",
       "      <td>0.603465</td>\n",
       "      <td>-0.603465</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>-0.132536</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>-0.186377</td>\n",
       "      <td>-0.167934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.599105</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>-0.084681</td>\n",
       "      <td>-0.088969</td>\n",
       "      <td>-0.251814</td>\n",
       "      <td>0.251814</td>\n",
       "      <td>0.288803</td>\n",
       "      <td>-0.288803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398452</th>\n",
       "      <td>2.869304</td>\n",
       "      <td>2.398711</td>\n",
       "      <td>0.068689</td>\n",
       "      <td>0.603465</td>\n",
       "      <td>-0.603465</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>-0.132536</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>-0.186377</td>\n",
       "      <td>-0.167934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.599105</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>-0.084681</td>\n",
       "      <td>-0.088969</td>\n",
       "      <td>3.971182</td>\n",
       "      <td>-3.971182</td>\n",
       "      <td>0.288803</td>\n",
       "      <td>-0.288803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398722</th>\n",
       "      <td>-0.129387</td>\n",
       "      <td>-0.361014</td>\n",
       "      <td>-0.195230</td>\n",
       "      <td>0.603465</td>\n",
       "      <td>-0.603465</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>-0.132536</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>-0.186377</td>\n",
       "      <td>-0.167934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.599105</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>-0.084681</td>\n",
       "      <td>-0.088969</td>\n",
       "      <td>-0.251814</td>\n",
       "      <td>0.251814</td>\n",
       "      <td>0.288803</td>\n",
       "      <td>-0.288803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398753</th>\n",
       "      <td>1.583771</td>\n",
       "      <td>1.314534</td>\n",
       "      <td>0.086809</td>\n",
       "      <td>0.603465</td>\n",
       "      <td>-0.603465</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>-0.132536</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>-0.186377</td>\n",
       "      <td>-0.167934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.599105</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>-0.084681</td>\n",
       "      <td>11.239804</td>\n",
       "      <td>3.971182</td>\n",
       "      <td>-3.971182</td>\n",
       "      <td>-3.462571</td>\n",
       "      <td>3.462571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398981</th>\n",
       "      <td>-0.312655</td>\n",
       "      <td>-0.410295</td>\n",
       "      <td>-0.157021</td>\n",
       "      <td>0.603465</td>\n",
       "      <td>-0.603465</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>-0.132536</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>-0.186377</td>\n",
       "      <td>-0.167934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.599105</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>-0.084681</td>\n",
       "      <td>-0.088969</td>\n",
       "      <td>-0.251814</td>\n",
       "      <td>0.251814</td>\n",
       "      <td>0.288803</td>\n",
       "      <td>-0.288803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399718</th>\n",
       "      <td>0.075130</td>\n",
       "      <td>-0.016048</td>\n",
       "      <td>-0.020729</td>\n",
       "      <td>0.603465</td>\n",
       "      <td>-0.603465</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>-0.132536</td>\n",
       "      <td>0.187734</td>\n",
       "      <td>-0.186377</td>\n",
       "      <td>-0.167934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067422</td>\n",
       "      <td>-0.599105</td>\n",
       "      <td>-0.277023</td>\n",
       "      <td>-0.063832</td>\n",
       "      <td>-0.084681</td>\n",
       "      <td>-0.088969</td>\n",
       "      <td>-0.251814</td>\n",
       "      <td>0.251814</td>\n",
       "      <td>0.288803</td>\n",
       "      <td>-0.288803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51036 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "index                                                                           \n",
       "2102214 -0.575605 -0.804541 -0.299616  0.603465 -0.603465 -0.133394 -0.132536   \n",
       "2103001  0.911788  0.772445  0.069083 -1.657097  1.657097 -0.133394  7.545127   \n",
       "2103003  2.300907  2.250869  0.355848  0.603465 -0.603465 -0.133394 -0.132536   \n",
       "2103009 -0.429522 -0.656699 -0.270073  0.603465 -0.603465 -0.133394 -0.132536   \n",
       "2103013  1.137553  0.969568  0.083263  0.603465 -0.603465 -0.133394 -0.132536   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "2398452  2.869304  2.398711  0.068689  0.603465 -0.603465 -0.133394 -0.132536   \n",
       "2398722 -0.129387 -0.361014 -0.195230  0.603465 -0.603465 -0.133394 -0.132536   \n",
       "2398753  1.583771  1.314534  0.086809  0.603465 -0.603465 -0.133394 -0.132536   \n",
       "2398981 -0.312655 -0.410295 -0.157021  0.603465 -0.603465 -0.133394 -0.132536   \n",
       "2399718  0.075130 -0.016048 -0.020729  0.603465 -0.603465 -0.133394 -0.132536   \n",
       "\n",
       "                7         8         9  ...        72        73        74  \\\n",
       "index                                  ...                                 \n",
       "2102214  0.187734 -0.186377 -0.167934  ... -0.067422 -0.599105 -0.277023   \n",
       "2103001  0.187734 -0.186377 -0.167934  ... -0.067422 -0.599105 -0.277023   \n",
       "2103003  0.187734 -0.186377 -0.167934  ... -0.067422 -0.599105 -0.277023   \n",
       "2103009  0.187734 -0.186377 -0.167934  ... -0.067422 -0.599105 -0.277023   \n",
       "2103013  0.187734 -0.186377 -0.167934  ... -0.067422 -0.599105 -0.277023   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "2398452  0.187734 -0.186377 -0.167934  ... -0.067422 -0.599105 -0.277023   \n",
       "2398722  0.187734 -0.186377 -0.167934  ... -0.067422 -0.599105 -0.277023   \n",
       "2398753  0.187734 -0.186377 -0.167934  ... -0.067422 -0.599105 -0.277023   \n",
       "2398981  0.187734 -0.186377 -0.167934  ... -0.067422 -0.599105 -0.277023   \n",
       "2399718  0.187734 -0.186377 -0.167934  ... -0.067422 -0.599105 -0.277023   \n",
       "\n",
       "               75        76         77        78        79        80        81  \n",
       "index                                                                           \n",
       "2102214 -0.063832 -0.084681  -0.088969 -0.251814  0.251814  0.288803 -0.288803  \n",
       "2103001 -0.063832 -0.084681  -0.088969  3.971182 -3.971182 -3.462571  3.462571  \n",
       "2103003 -0.063832 -0.084681  11.239804  3.971182 -3.971182 -3.462571  3.462571  \n",
       "2103009 -0.063832 -0.084681  -0.088969 -0.251814  0.251814  0.288803 -0.288803  \n",
       "2103013 -0.063832 -0.084681  -0.088969 -0.251814  0.251814  0.288803 -0.288803  \n",
       "...           ...       ...        ...       ...       ...       ...       ...  \n",
       "2398452 -0.063832 -0.084681  -0.088969  3.971182 -3.971182  0.288803 -0.288803  \n",
       "2398722 -0.063832 -0.084681  -0.088969 -0.251814  0.251814  0.288803 -0.288803  \n",
       "2398753 -0.063832 -0.084681  11.239804  3.971182 -3.971182 -3.462571  3.462571  \n",
       "2398981 -0.063832 -0.084681  -0.088969 -0.251814  0.251814  0.288803 -0.288803  \n",
       "2399718 -0.063832 -0.084681  -0.088969 -0.251814  0.251814  0.288803 -0.288803  \n",
       "\n",
       "[51036 rows x 82 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.loc[is_0.astype(bool)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_0 = model_detect_0.predict(X_test).astype(bool)\n",
    "y_pred_not_0 = model_regr.predict(X_test[~is_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.zeros(y_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16782694569307008"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test[~is_0], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014074807696125803"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test[is_0], np.zeros(is_0.sum()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
